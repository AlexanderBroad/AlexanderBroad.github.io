{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59bd112e",
   "metadata": {},
   "source": [
    "# Generating Chorales With RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8080f88c",
   "metadata": {},
   "source": [
    "# Getting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d3ad52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.keras.utils.get_file(\n",
    "    \"jsb_chorales.tgz\",\n",
    "    \"https://github.com/ageron/data/raw/main/jsb_chorales.tgz\",\n",
    "    cache_dir=\".\",\n",
    "    extract=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a08dcd2",
   "metadata": {},
   "source": [
    "The first cell imports the tensorflow library, then downloads music data in a compressed tar file from a github repository. It then extracts the contents of the tar file to the current directory, where the notebook is stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06abc3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "jsb_chorales_dir = Path(\"datasets/jsb_chorales\")\n",
    "train_files = sorted(jsb_chorales_dir.glob(\"train/chorale_*.csv\"))\n",
    "valid_files = sorted(jsb_chorales_dir.glob(\"valid/chorale_*.csv\"))\n",
    "test_files = sorted(jsb_chorales_dir.glob(\"test/chorale_*.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3073c9",
   "metadata": {},
   "source": [
    "The cell above imports the 'Path' class from the 'pathlib' module, which is a useful tool when working with file paths in Python. It then finds the previously downloaded music data, which was organised in three sections, 'train', 'valid', and 'test', sorts the data in alphabetical order, and stores the lists of file paths in three variables, 'train_files', 'valid_files', and 'test_files'. This is done so that in the next cell we can call these variables to read the data that was downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23de8b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_chorales(filepaths):\n",
    "    return [pd.read_csv(filepath).values.tolist() for filepath in filepaths]\n",
    "\n",
    "train_chorales = load_chorales(train_files)\n",
    "valid_chorales = load_chorales(valid_files)\n",
    "test_chorales = load_chorales(test_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3592633",
   "metadata": {},
   "source": [
    "The cell above first imports the pandas library, a data analysis and manipulation tool for Python. Then the code defines a function called 'load_chorales' that can read the music files and return their data as lists. It then calls this function three times, once for each type of file (training, validation, and test), and assigns the results to the variables 'train_chorales', 'valid_chorales', and 'test_chorales', respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebca341",
   "metadata": {},
   "source": [
    "# Preparing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953b8890",
   "metadata": {},
   "outputs": [],
   "source": [
    "notes = set()\n",
    "for chorales in (train_chorales, valid_chorales, test_chorales):\n",
    "    for chorale in chorales:\n",
    "        for chord in chorale:\n",
    "            notes |= set(chord)\n",
    "\n",
    "n_notes = len(notes)\n",
    "min_note = min(notes - {0}) #0 denotes no notes being played\n",
    "max_note = max(notes)\n",
    "\n",
    "assert min_note == 36\n",
    "assert max_note == 81"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f276f7",
   "metadata": {},
   "source": [
    "The cell above checks all the notes contained within the chorales we downloaded earlier, finds the minimum and maximum notes, then checks that the notes are within an expected range of 36 to 81. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a4f254",
   "metadata": {},
   "source": [
    "### Code for Synthesiser\n",
    "\n",
    "The following cell is code for a synthesiser to play MIDI. Not part of machine learning code to generate Bach, but useful for listening to the results and samples used for training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bc04ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "import numpy as np\n",
    "\n",
    "def notes_to_frequencies(notes):\n",
    "    # Frequency doubles when you go up one octave; there are 12 semi-tones\n",
    "    # per octave; Note A on octave 4 is 440 Hz, and it is note number 69.\n",
    "    return 2 ** ((np.array(notes) - 69) / 12) * 440\n",
    "\n",
    "def frequencies_to_samples(frequencies, tempo, sample_rate):\n",
    "    note_duration = 60 / tempo # the tempo is measured in beats per minutes\n",
    "    # To reduce click sound at every beat, we round the frequencies to try to\n",
    "    # get the samples close to zero at the end of each note.\n",
    "    frequencies = (note_duration * frequencies).round() / note_duration\n",
    "    n_samples = int(note_duration * sample_rate)\n",
    "    time = np.linspace(0, note_duration, n_samples)\n",
    "    sine_waves = np.sin(2 * np.pi * frequencies.reshape(-1, 1) * time)\n",
    "    # Removing all notes with frequencies â‰¤ 9 Hz (includes note 0 = silence)\n",
    "    sine_waves *= (frequencies > 9.).reshape(-1, 1)\n",
    "    return sine_waves.reshape(-1)\n",
    "\n",
    "def chords_to_samples(chords, tempo, sample_rate):\n",
    "    freqs = notes_to_frequencies(chords)\n",
    "    freqs = np.r_[freqs, freqs[-1:]] # make last note a bit longer\n",
    "    merged = np.mean([frequencies_to_samples(melody, tempo, sample_rate)\n",
    "                     for melody in freqs.T], axis=0)\n",
    "    n_fade_out_samples = sample_rate * 60 // tempo # fade out last note\n",
    "    fade_out = np.linspace(1., 0., n_fade_out_samples)**2\n",
    "    merged[-n_fade_out_samples:] *= fade_out\n",
    "    return merged\n",
    "\n",
    "def play_chords(chords, tempo=160, amplitude=0.1, sample_rate=44100, filepath=None):\n",
    "    samples = amplitude * chords_to_samples(chords, tempo, sample_rate)\n",
    "    if filepath:\n",
    "        from scipy.io import wavfile\n",
    "        samples = (2**15 * samples).astype(np.int16)\n",
    "        wavfile.write(filepath, sample_rate, samples)\n",
    "        return display(Audio(filepath))\n",
    "    else:\n",
    "        return display(Audio(samples, rate=sample_rate))\n",
    "\n",
    "## testing the synthesiser\n",
    "for index in range(3):\n",
    "    play_chords(train_chorales[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c315b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def create_target(batch):\n",
    "    X = batch[:, :-1]\n",
    "    Y = batch[:, 1:] # predict next note in each arpegio, at each step\n",
    "    return X, Y\n",
    "\n",
    "def preprocess(window):\n",
    "    window = tf.where(window == 0, window, window - min_note + 1) # shift values\n",
    "    return tf.reshape(window, [-1]) # convert to arpegio\n",
    "\n",
    "def bach_dataset(chorales, batch_size=32, shuffle_buffer_size=None,\n",
    "                 window_size=32, window_shift=16, cache=True):\n",
    "    def batch_window(window):\n",
    "        return window.batch(window_size + 1)\n",
    "\n",
    "    def to_windows(chorale):\n",
    "        dataset = tf.data.Dataset.from_tensor_slices(chorale)\n",
    "        dataset = dataset.window(window_size + 1, window_shift, drop_remainder=True)\n",
    "        return dataset.flat_map(batch_window)\n",
    "\n",
    "    chorales = tf.ragged.constant(chorales, ragged_rank=1)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(chorales)\n",
    "    dataset = dataset.flat_map(to_windows).map(preprocess)\n",
    "    if cache:\n",
    "        dataset = dataset.cache()\n",
    "    if shuffle_buffer_size:\n",
    "        dataset = dataset.shuffle(shuffle_buffer_size)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.map(create_target)\n",
    "    return dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0076e9",
   "metadata": {},
   "source": [
    "In this cell, the chorales are organised into a format that the machine learning algorithm we will employ later can use. The algorithm breaks each musical composition into small sections called 'windows', then looks at each of these windows, the existing patterns and relationships between notes, to try to predict what the next note will be. It is essentially learning to replicate the musical style of Bach by analysing the compositions we have provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b547f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = bach_dataset(train_chorales, shuffle_buffer_size=1000)\n",
    "valid_set = bach_dataset(valid_chorales)\n",
    "test_set = bach_dataset(test_chorales)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d361c4",
   "metadata": {},
   "source": [
    "This cell creates three separate datasets from the lists of chorales we sorted earlier. The first dataset 'train_set' contains the 'shuffle_buffer_size', set to 1000. This means the function will randomly shuffle the order of the chorales 1000 times, so it doesn't memorise patterns in the training data. This will improve the model's ability to generalise to unseen data. The other data sets will be used for validation and testing respectively, so they shouldn't be shuffled."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa66a40",
   "metadata": {},
   "source": [
    "# Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b35ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_embedding_dims = 5\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=n_notes, output_dim=n_embedding_dims,\n",
    "                           input_shape=[None]),\n",
    "    tf.keras.layers.Conv1D(32, kernel_size=2, padding=\"causal\", activation=\"relu\"),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Conv1D(48, kernel_size=2, padding=\"causal\", activation=\"relu\", dilation_rate=2),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Conv1D(64, kernel_size=2, padding=\"causal\", activation=\"relu\", dilation_rate=4),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Conv1D(96, kernel_size=2, padding=\"causal\", activation=\"relu\", dilation_rate=8),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.LSTM(256, return_sequences=True),\n",
    "    tf.keras.layers.Dense(n_notes, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6a0d5e",
   "metadata": {},
   "source": [
    "The cell defines the architecture of a deep neural network using the Keras library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330c181e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e94dc5",
   "metadata": {},
   "source": [
    "This cell returns a summary of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18d5028",
   "metadata": {},
   "source": [
    "# Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7682f58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Nadam(learning_rate=1e-3)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_set, epochs=20, validation_data=valid_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de75318",
   "metadata": {},
   "source": [
    "The cell above defines and trains the neural network model. The number of epochs means the model will iterate through the training data 20 times, each time evaluating its performance on the validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e9dbdf",
   "metadata": {},
   "source": [
    "# Saving and Evaluating Your Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cea7b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_bach_model\", save_format=\"tf\")\n",
    "model.evaluate(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2c6226",
   "metadata": {},
   "source": [
    "This cell saves the trained model to a file called 'my_bach_model', then evaluates the model's performance using the test data set we defined earlier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f1e7c1",
   "metadata": {},
   "source": [
    "# Generating Chorales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a628834",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_chorale_v2(model, seed_chords, length, temperature=1):\n",
    "    arpegio = preprocess(tf.constant(seed_chords, dtype=tf.int64))\n",
    "    arpegio = tf.reshape(arpegio, [1, -1])\n",
    "    for chord in range(length):\n",
    "        for note in range(4):\n",
    "            next_note_probas = model.predict(arpegio)[0, -1:]\n",
    "            rescaled_logits = tf.math.log(next_note_probas) / temperature\n",
    "            next_note = tf.random.categorical(rescaled_logits, num_samples=1)\n",
    "            arpegio = tf.concat([arpegio, next_note], axis=1)\n",
    "    arpegio = tf.where(arpegio == 0, arpegio, arpegio + min_note - 1)\n",
    "    return tf.reshape(arpegio, shape=[-1, 4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6a4d5d",
   "metadata": {},
   "source": [
    "The cell above defines the function 'generate_chorale_v2' which takes the model, seed chords, and length as inputs, then generates a chorale with a specified length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026e17c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_chords = test_chorales[2][:8]\n",
    "play_chords(seed_chords, amplitude=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4008582b",
   "metadata": {},
   "source": [
    "This cell selects a subset of chords from the variable 'test_chorales', then plays those chords with the synthesiser and an amplitude of 0.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b9f623",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_chorale_v2_cold = generate_chorale_v2(model, seed_chords, 56, temperature=0.8)\n",
    "play_chords(new_chorale_v2_cold, filepath=\"bach_cold.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26bfdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_chorale_v2_medium = generate_chorale_v2(model, seed_chords, 56, temperature=1.0)\n",
    "play_chords(new_chorale_v2_medium, filepath=\"bach_medium.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48734911",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_chorale_v2_hot = generate_chorale_v2(model, seed_chords, 56, temperature=1.5)\n",
    "play_chords(new_chorale_v2_hot, filepath=\"bach_hot2.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d918eb9",
   "metadata": {},
   "source": [
    "The three cells above all perform the same function: generating new chorales using the model we have built and trained. Note that the 'temperature' paramater controls the randomness of the generated notes, hence the three newly generated chorale audio files are defined at three different temperatures, from 'bach_cold.wav', which has the least 'randomness' in its generated notes with a temperature parameter set to '0.8', to 'bach_hot.wav' which has a temperature of '1.5', and is the most 'random' in its note generation. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
